{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMTrainer(object):\n",
    "    def __init__(self, kernel, c):\n",
    "        self._kernel = kernel\n",
    "        self._c = c\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Given the training features X with labels y, returns a SVM\n",
    "        predictor representing the trained SVM.\n",
    "        \"\"\"\n",
    "        lagrange_multipliers = self._compute_multipliers(X, y)\n",
    "        return self._construct_predictor(X, y, lagrange_multipliers)\n",
    "\n",
    "    def _gram_matrix(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        # TODO(tulloch) - vectorize\n",
    "        for i, x_i in enumerate(X):\n",
    "            for j, x_j in enumerate(X):\n",
    "                K[i, j] = self._kernel(x_i, x_j)\n",
    "        return K\n",
    "\n",
    "    def _construct_predictor(self, X, y, lagrange_multipliers):\n",
    "        support_vector_indices = \\\n",
    "            lagrange_multipliers > 1e-7 #MIN_SUPPORT_VECTOR_MULTIPLIER\n",
    "\n",
    "        support_multipliers = lagrange_multipliers[support_vector_indices]\n",
    "        support_vectors = X[support_vector_indices]\n",
    "        support_vector_labels = y[support_vector_indices]\n",
    "\n",
    "        # http://www.cs.cmu.edu/~guestrin/Class/10701-S07/Slides/kernels.pdf\n",
    "        # bias = y_k - \\sum z_i y_i  K(x_k, x_i)\n",
    "        # Thus we can just predict an example with bias of zero, and\n",
    "        # compute error.\n",
    "        bias = np.mean(\n",
    "            [y_k - SVMPredictor(\n",
    "                kernel=self._kernel,\n",
    "                bias=0.0,\n",
    "                weights=support_multipliers,\n",
    "                support_vectors=support_vectors,\n",
    "                support_vector_labels=support_vector_labels).predict(x_k)\n",
    "             for (y_k, x_k) in zip(support_vector_labels, support_vectors)])\n",
    "        print(support_vectors.shape)\n",
    "\n",
    "        return SVMPredictor(\n",
    "            kernel=self._kernel,\n",
    "            bias=bias,\n",
    "            weights=support_multipliers,\n",
    "            support_vectors=support_vectors,\n",
    "            support_vector_labels=support_vector_labels)\n",
    "\n",
    "    def _compute_multipliers(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        K = self._gram_matrix(X)\n",
    "        # Solves\n",
    "        # min 1/2 x^T P x + q^T x\n",
    "        # s.t.\n",
    "        #  Gx \\coneleq h\n",
    "        #  Ax = b\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y, y) * K)\n",
    "        q = cvxopt.matrix(-1 * np.ones(n_samples))\n",
    "\n",
    "        # -a_i \\leq 0\n",
    "        # TODO(tulloch) - modify G, h so that we have a soft-margin classifier\n",
    "        G_std = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "        h_std = cvxopt.matrix(np.zeros(n_samples))\n",
    "\n",
    "        # a_i \\leq c\n",
    "        G_slack = cvxopt.matrix(np.diag(np.ones(n_samples)))\n",
    "        h_slack = cvxopt.matrix(np.ones(n_samples) * self._c)\n",
    "\n",
    "        G = cvxopt.matrix(np.vstack((G_std, G_slack)))\n",
    "        h = cvxopt.matrix(np.vstack((h_std, h_slack)))\n",
    "\n",
    "        A = cvxopt.matrix(y, (1, n_samples))\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMPredictor(object):\n",
    "    def __init__(self,\n",
    "                 kernel,\n",
    "                 bias,\n",
    "                 weights,\n",
    "                 support_vectors,\n",
    "                 support_vector_labels):\n",
    "        self._kernel = kernel\n",
    "        self._bias = bias\n",
    "        self._weights = weights\n",
    "        self._support_vectors = support_vectors\n",
    "        self._support_vector_labels = support_vector_labels\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Computes the SVM prediction on the given features x.\n",
    "        \"\"\"\n",
    "        result = self._bias\n",
    "        #print(self._support_vectors.shape)\n",
    "        #print(x.shape)\n",
    "        for z_i, x_i, y_i in zip(self._weights,\n",
    "                                 self._support_vectors,\n",
    "                                 self._support_vector_labels):\n",
    "            result += z_i * y_i * self._kernel(x_i, x)\n",
    "\n",
    "        return np.sign(result).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "\n",
    "class Kernel(object):\n",
    "    \"\"\"Implements list of kernels from\n",
    "    http://en.wikipedia.org/wiki/Support_vector_machine\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def linear():\n",
    "        def f(x, y):\n",
    "            return np.inner(x, y)\n",
    "        return f\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian(sigma):\n",
    "        def f(x, y):\n",
    "            exponent = -np.sqrt(la.norm(x-y) ** 2 / (2 * sigma ** 2))\n",
    "            return np.exp(exponent)\n",
    "        return f\n",
    "\n",
    "    @staticmethod\n",
    "    def _polykernel(dimension, offset):\n",
    "        def f(x, y):\n",
    "            return (offset + np.dot(x, y)) ** dimension\n",
    "        return f\n",
    "\n",
    "    @staticmethod\n",
    "    def inhomogenous_polynomial(dimension):\n",
    "        return Kernel._polykernel(dimension=dimension, offset=1.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def homogenous_polynomial(dimension):\n",
    "        return Kernel._polykernel(dimension=dimension, offset=0.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperbolic_tangent(kappa, c):\n",
    "        def f(x, y):\n",
    "            return np.tanh(kappa * np.dot(x, y) + c)\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "#import argh\n",
    "\n",
    "\n",
    "def example(num_samples=10, num_features=2, grid_size=20, filename=\"svm.pdf\"):\n",
    "    samples = np.matrix(np.random.normal(size=num_samples * num_features)\n",
    "                        .reshape(num_samples, num_features))\n",
    "    labels = 2 * (samples.sum(axis=1) > 0) - 1.0\n",
    "    trainer = SVMTrainer(Kernel.linear(), 0.1)\n",
    "    predictor = trainer.train(samples, labels)\n",
    "\n",
    "    plot(predictor, samples, labels, grid_size, filename)\n",
    "\n",
    "\n",
    "def plot(predictor, X, y, grid_size, filename):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, grid_size),\n",
    "                         np.linspace(y_min, y_max, grid_size),\n",
    "                         indexing='ij')\n",
    "    flatten = lambda m: np.array(m).reshape(-1,)\n",
    "\n",
    "    result = []\n",
    "    for (i, j) in itertools.product(range(grid_size), range(grid_size)):\n",
    "        point = np.array([xx[i, j], yy[i, j]]).reshape(1, 2)\n",
    "        result.append(predictor.predict(point))\n",
    "\n",
    "    Z = np.array(result).reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z,\n",
    "                 cmap=cm.Paired,\n",
    "                 levels=[-0.001, 0.001],\n",
    "                 extend='both',\n",
    "                 alpha=0.8)\n",
    "    plt.scatter(flatten(X[:, 0]), flatten(X[:, 1]),\n",
    "                c=flatten(y), cmap=cm.Paired)\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    " #   logging.basicConfig(level=logging.ERROR)\n",
    " #   argh.dispatch_command(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8894e+00 -2.0253e+00  4e+01  6e+00  2e-16\n",
      " 1: -6.4355e-01 -1.8345e+00  2e+00  1e-01  5e-16\n",
      " 2: -6.0085e-01 -7.8032e-01  2e-01  7e-17  5e-16\n",
      " 3: -6.6483e-01 -6.8258e-01  2e-02  5e-17  2e-16\n",
      " 4: -6.7427e-01 -6.7452e-01  2e-04  7e-17  1e-16\n",
      " 5: -6.7443e-01 -6.7443e-01  2e-06  6e-17  2e-16\n",
      " 6: -6.7443e-01 -6.7443e-01  2e-08  5e-17  2e-16\n",
      "Optimal solution found.\n",
      "(8, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
